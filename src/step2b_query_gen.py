
"""
é“¶è¡ŒåŒ¹é…é¡¹ç›® - ç¬¬äºŒæ­¥Bï¼šAIç”ŸæˆæŸ¥è¯¢è¯­å¥

æœ¬è„šæœ¬ä½¿ç”¨AIå¤§æ¨¡å‹å¯¹ç»è¿‡åˆ†ç±»ç¡®è®¤çš„é“¶è¡Œå®ä½“åç§°è¿›è¡Œæ·±åº¦æ¸…æ´—å’Œæ ‡å‡†åŒ–å¤„ç†ï¼Œ
ä¸ºåç»­åœ¨FDICæ•°æ®åº“ä¸­è¿›è¡Œç²¾ç¡®åŒ¹é…åšå‡†å¤‡ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. è¯»å–ç¬¬äºŒæ­¥Aåˆ†ç±»åçš„é“¶è¡Œå®ä½“åå•
2. åˆ©ç”¨AIå¤§æ¨¡å‹å¯¹é“¶è¡Œåç§°è¿›è¡Œæ™ºèƒ½æ¸…æ´—å’Œæ ‡å‡†åŒ–ï¼š
   - è¿˜åŸé“¶è¡Œå…¨ç§°ï¼ˆå¦‚"BofA" â†’ "Bank of America"ï¼‰
   - æå–æ ¸å¿ƒæœç´¢åç§°ï¼ˆå»é™¤æ³•å¾‹åç¼€å’Œæ ‡ç‚¹ç¬¦å·ï¼‰
   - æå–å‰èº«é“¶è¡Œåç§°ï¼ˆå¦‚æœ‰"[Ex-Name]"æ ‡è®°ï¼‰
   - ä¼°ç®—é“¶è¡Œå½“å‰çŠ¶æ€ï¼ˆæ´»è·ƒ/å€’é—­/è¢«æ”¶è´­ï¼‰
3. ç”Ÿæˆä¸“é—¨ç”¨äºFDIC APIæŸ¥è¯¢çš„è½¬ä¹‰å­—ç¬¦ä¸²
4. æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œé¿å…é‡å¤å¤„ç†å·²æ¸…æ´—çš„å®ä½“
5. å°†å¤„ç†ç»“æœä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­ä¾›ç¬¬ä¸‰æ­¥ä½¿ç”¨

å…³é”®è¾“å‡ºå­—æ®µï¼š
- `clean_legal_name`: æ¸…æ´—åçš„é“¶è¡Œæ³•å®šå…¨ç§°
- `search_core_name`: æ ¸å¿ƒæœç´¢åç§°ï¼ˆç”¨äºç®—æ³•åŒ¹é…ï¼‰
- `fdic_query_main`: ä¸»ä½“é“¶è¡Œçš„FDIC APIæŸ¥è¯¢å­—ç¬¦ä¸²
- `predecessor`: å‰èº«é“¶è¡Œåç§°ï¼ˆå¦‚æœ‰ï¼‰
- `fdic_query_pred`: å‰èº«é“¶è¡Œçš„FDIC APIæŸ¥è¯¢å­—ç¬¦ä¸²

"""

import pandas as pd
import os
import sys
import json
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
# âœ… ä¿®æ”¹ç‚¹ 1: å¯¼å…¥ç«å±±å¼•æ“å®˜æ–¹ Ark SDK
from volcenginesdkarkruntime import Ark

# å‡è®¾ config.py åœ¨ä¸Šä¸€çº§ç›®å½•
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

# ================= 1. æç¤ºè¯ (çº¯æ¨ç†ç‰ˆ) =================
PROMPT_QUERY = """
Role: Financial Entity Analyst.
Task: Normalize bank names for FDIC database matching based on your internal knowledge.

Input: Raw bank names from Dealscan (e.g., "BofA", "WestLB AG [Toronto]", "ABSA Bank [Ex-Amalgamated]").

Your Goal is to generate a structured JSON with specific cleaned fields:

1. **`clean_legal_name`**: Restore the full legal name based on common financial knowledge.
   - Expand abbreviations (e.g., "BofA" -> "Bank of America").
   - **REMOVE** location/branch info (e.g., remove "[Toronto]", "New York Branch").

2. **`search_core_name` (CRITICAL)**: Create a version STRICTLY for search algorithms.
   - **REMOVE** legal suffixes: "Inc", "Corp", "Ltd", "LLC", "N.A.", "AG", "SA", "NV", "BV", "Plc", "Sarl", "SpA".
   - **KEEP** "Bank" or "Bancorp".
   - **REMOVE** punctuation & extra spaces.
   - Example: "Bank of America, N.A." -> "Bank of America"

3. **`predecessor_name`**: If the name contains "[Ex-Name]", extract the former name.

4. **`status`**: Estimate status ("Active", "Failed", "Acquired") based on your knowledge.

Output: JSON Array ONLY.

Example Output:
[
  {
    "original": "WestLB AG [Toronto]", 
    "clean_legal_name": "WestLB AG", 
    "search_core_name": "WestLB", 
    "predecessor_name": null, 
    "status": "Failed"
  }
]
"""


# ================= 2. å·¥å…·å‡½æ•° =================

def init_client():
    # âœ… ä¿®æ”¹ç‚¹ 2: åˆå§‹åŒ– Ark å®¢æˆ·ç«¯
    # å®˜æ–¹ SDK ä¼šè‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡ ARK_API_KEYï¼Œä¹Ÿå¯ä»¥æ˜¾å¼ä¼ å…¥
    return Ark(
        base_url="https://ark.cn-beijing.volces.com/api/v3",
        api_key=config.ARK_API_KEY
    )


def parse_json(raw):
    """é²æ£’çš„ JSON è§£æå™¨"""
    try:
        if not raw: return None
        clean_raw = raw.strip()
        if clean_raw.startswith("```"):
            clean_raw = re.sub(r'^```json\s*|^```\s*|```$', '', clean_raw, flags=re.MULTILINE)

        if clean_raw.startswith('[') or clean_raw.startswith('{'):
            data = json.loads(clean_raw)
            if isinstance(data, dict):
                return data.get("results") or data.get("banks") or [data]
            return data
    except:
        pass
    return None


def finalize_fdic_query(core_name):
    """ç”Ÿæˆ FDIC API ä¸“ç”¨çš„è½¬ä¹‰æŸ¥è¯¢ä¸²"""
    if not core_name or pd.isna(core_name) or len(str(core_name)) < 2:
        return None

    clean = str(core_name).upper().strip()
    clean = re.sub(r'[^A-Z0-9\s]', '', clean)
    clean = re.sub(r'\s+', ' ', clean)

    if not clean: return None

    # è½¬ä¹‰ç©ºæ ¼: "BANK OF AMERICA" -> "BANK\ OF\ AMERICA"
    escaped_name = clean.replace(' ', r'\ ')
    return f"NAME:*{escaped_name}*"


# ================= 3. ä¸»é€»è¾‘ =================

def run():
    print(f"ğŸš€ [Step 2b] AI åç§°æ¸…æ´— (Ark SDK) - çº¯æ¨ç†æ¨¡å¼...")

    # 1. ç¡®å®šè¾“å…¥æ–‡ä»¶
    input_file = "unique_lenders_all_years.csv"
    output_file = config.LENDERS_WITH_QUERIES_FILE

    if not os.path.exists(input_file):
        input_file = config.CLASSIFIED_LENDERS_FILE
        if not os.path.exists(input_file):
            print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶")
            return

    print(f"ğŸ“‚ è¯»å–æ–‡ä»¶: {input_file}")
    df = pd.read_csv(input_file)

    col_name = 'Lender_Name' if 'Lender_Name' in df.columns else 'name'

    if 'is_bank' in df.columns:
        df['is_bank'] = df['is_bank'].astype(str).str.lower() == 'true'
        candidates = df[df['is_bank']][col_name].unique().tolist()
    else:
        candidates = df[col_name].dropna().unique().tolist()

    print(f"ğŸ“Š å¾…æ¸…æ´—é“¶è¡Œæ•°: {len(candidates)}")

    # æ–­ç‚¹ç»­ä¼ 
    processed = set()
    if os.path.exists(output_file):
        try:
            processed = set(pd.read_csv(output_file)['original'].astype(str))
            print(f"ğŸ“‚ è·³è¿‡å·²å¤„ç†: {len(processed)} æ¡")
        except:
            pass

    to_process = [n for n in candidates if str(n) not in processed and len(str(n)) > 1]

    if not to_process:
        print("âœ… æ‰€æœ‰åå•å·²å¤„ç†å®Œæ¯•ï¼")
        return

    client = init_client()
    batches = [to_process[i:i + config.BATCH_SIZE_QUERY] for i in range(0, len(to_process), config.BATCH_SIZE_QUERY)]

    def process_batch(batch):
        try:
            # âœ… ä¿®æ”¹ç‚¹ 3: ä½¿ç”¨ Ark SDK çš„æ ‡å‡†è°ƒç”¨æ–¹å¼
            # ç§»é™¤äº† tools å‚æ•°ï¼Œçº¯æ¨ç†é€Ÿåº¦æå¿«ï¼Œä¸”ä¸ä¼šæŠ¥ 400 é”™è¯¯
            completion = client.chat.completions.create(
                model=config.MODEL_REASONING,
                messages=[
                    {"role": "system", "content": PROMPT_QUERY},
                    {"role": "user", "content": "Analyze list:\n" + "\n".join(str(x) for x in batch)}
                ],
                temperature=0.01
            )

            ai_results = parse_json(completion.choices[0].message.content) or []

            final_rows = []
            for item in ai_results:
                orig = item.get('original')
                core_name = item.get('search_core_name')
                predecessor = item.get('predecessor_name')

                final_rows.append({
                    "original": orig,
                    "clean_legal_name": item.get('clean_legal_name'),
                    "search_core_name": core_name,
                    "predecessor": predecessor,
                    "status": item.get('status'),
                    "successor": item.get('successor'),
                    "fdic_query_main": finalize_fdic_query(core_name),
                    "fdic_query_pred": finalize_fdic_query(predecessor)
                })
            return final_rows

        except Exception as e:
            print(f"âš ï¸ Batch Error: {e}")
            return []

    # å¹¶å‘æ‰§è¡Œ
    results_buffer = []
    with ThreadPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
        futures = {executor.submit(process_batch, batch): batch for batch in batches}

        for future in tqdm(as_completed(futures), total=len(batches), desc="AI Cleaning"):
            res = future.result()
            if res: results_buffer.extend(res)

            if len(results_buffer) >= (config.BATCH_SIZE_QUERY * 2):
                df_res = pd.DataFrame(results_buffer)
                write_header = not os.path.exists(output_file)
                df_res.to_csv(output_file, mode='a', index=False, header=write_header)
                results_buffer = []

    if results_buffer:
        df_res = pd.DataFrame(results_buffer)
        write_header = not os.path.exists(output_file)
        df_res.to_csv(output_file, mode='a', index=False, header=write_header
                      )

    print(f"ğŸ‰ æ¸…æ´—å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    print("ğŸ‘‰ ä¸‹ä¸€æ­¥: è¿è¡Œ Step 3 (Python)ï¼Œä»£ç ä¼šè‡ªåŠ¨è¯»å– 'fdic_query_main' åˆ—è¿›è¡Œæœç´¢ã€‚")


if __name__ == "__main__":
    run()