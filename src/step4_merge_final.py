import pandas as pd
import os
import sys
import glob
import re

# å¯¼å…¥é…ç½®
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config


# ================= è¾…åŠ©å‡½æ•° =================

def clean_id(val):
    """
    æ ‡å‡†åŒ– ID æ ¼å¼ (å»é™¤ .0ï¼Œè½¬å­—ç¬¦ä¸²)
    """
    if pd.isna(val) or str(val).strip() == '' or str(val).lower() in ['nan', 'none']:
        return None
    try:
        return str(int(float(val)))
    except:
        return str(val).strip()


def load_master_map():
    """
    è¯»å–ä¸»æ˜ å°„è¡¨ï¼Œæå–ç”¨äºå»ºç«‹è¿æ¥çš„ RSSDã€‚
    """
    map_file = config.MASTER_MAPPING_FILE
    if not os.path.exists(map_file):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°ä¸»æ˜ å°„è¡¨: {map_file}")

    print(f"ğŸ“– æ­£åœ¨åŠ è½½ä¸»æ˜ å°„è¡¨: {map_file}")
    df_map = pd.read_csv(map_file)

    # åªéœ€è¦ä¿ç•™ç”¨äºåŒ¹é…çš„åˆ—ï¼šLender_Name å’Œ Match1-5 çš„ RSSD
    cols_to_keep = ['Lender_Name_Input']
    for i in range(1, 6):
        cols_to_keep.append(f'Match{i}_RSSD')

    cols_to_keep = [c for c in cols_to_keep if c in df_map.columns]
    df_clean = df_map[cols_to_keep].copy()

    # æ¸…æ´— RSSD
    for c in df_clean.columns:
        if 'RSSD' in c:
            df_clean[c] = df_clean[c].apply(clean_id)

    # è‡³å°‘ Match1 è¦æœ‰ RSSD
    if 'Match1_RSSD' in df_clean.columns:
        df_clean = df_clean.dropna(subset=['Match1_RSSD'])

    print(f"   -> åŠ è½½äº† {len(df_clean)} æ¡æœ‰æ•ˆæ˜ å°„")
    return df_clean


# ================= ä¸»é€»è¾‘ =================

def run():
    print("ğŸš€ [Step 4] å¼€å§‹æœ€ç»ˆåˆå¹¶ (æç®€è¾“å‡ºç‰ˆ)...")

    # 1. åŠ è½½æ˜ å°„å…³ç³»
    try:
        df_map = load_master_map()
    except FileNotFoundError as e:
        print(e)
        return

    # 2. æŸ¥æ‰¾ Call Report æ–‡ä»¶
    call_files = glob.glob(os.path.join(config.DIR_CALL, "*call*.csv"))
    if not call_files:
        print(f"âŒ æœªæ‰¾åˆ° Call Report æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ {config.DIR_CALL}")
        return

    # 3. é€å¹´å¤„ç†
    for call_path in call_files:
        filename = os.path.basename(call_path)
        year_match = re.search(r'20\d{2}', filename)
        if not year_match: continue
        year = int(year_match.group(0))

        print(f"\nğŸ“… æ­£åœ¨å¤„ç†: {filename} (Year {year})")

        # --- 3.1 è¯»å– Call Report ---
        try:
            # ç®€åŒ–è¯»å–ï¼Œåªè¯»éœ€è¦çš„åˆ— + è¿æ¥é”®
            # å‡è®¾ CSV é‡Œè‚¯å®šæœ‰è¿™äº›åˆ—ï¼Œæ²¡æœ‰ä¼šæŠ¥é”™
            df_call = pd.read_csv(call_path)
            # ç»Ÿä¸€åˆ—åå°å†™
            df_call.columns = [c.strip().lower().replace('\ufeff', '') for c in df_call.columns]

            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
            req_call_cols = ['rssdid', 'name']
            if not all(c in df_call.columns for c in req_call_cols):
                print(f"   âŒ Call Report ç¼ºå°‘å¿…è¦åˆ— {req_call_cols}ï¼Œè·³è¿‡")
                continue

            # è¡¥å…¨/æ¸…æ´—
            if 'year' not in df_call.columns: df_call['year'] = year
            df_call['rssdid'] = df_call['rssdid'].apply(clean_id)
            df_call['year'] = pd.to_numeric(df_call['year'], errors='coerce').fillna(0).astype(int)

            # å¤„ç† quarter
            if 'quarter' in df_call.columns:
                df_call['quarter'] = pd.to_numeric(df_call['quarter'], errors='coerce').fillna(0).astype(int)
            else:
                # å¦‚æœæ²¡æœ‰ quarter åˆ—ï¼Œå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œå…ˆèµ‹é»˜è®¤å€¼æˆ–è·³è¿‡
                print("   âš ï¸ Call Report ç¼ºå°‘ quarter åˆ—ï¼Œè®¾ä¸º 0")
                df_call['quarter'] = 0

            # åªä¿ç•™éœ€è¦çš„åˆ—
            df_call = df_call[['year', 'quarter', 'rssdid', 'name']]

        except Exception as e:
            print(f"   âŒ è¯»å– Call Report å¤±è´¥: {e}")
            continue

        # --- 3.2 è¯»å– DealScan å¹¶å…³è” Mapping ---
        ds_pattern = os.path.join(config.DIR_DEALSCAN, f"dealscan_*{year}*.csv")
        ds_files = glob.glob(ds_pattern)

        df_lookup = pd.DataFrame()

        if ds_files:
            try:
                ds_file = ds_files[0]
                cols_to_use = ['Lender_Name', 'Lender_Id', 'year', 'quarter']

                try:
                    df_ds = pd.read_csv(ds_file, usecols=cols_to_use, encoding='utf-8')
                except UnicodeDecodeError:
                    df_ds = pd.read_csv(ds_file, usecols=cols_to_use, encoding='ISO-8859-1')

                df_ds['Lender_Id'] = df_ds['Lender_Id'].apply(clean_id)
                df_ds['year'] = pd.to_numeric(df_ds['year'], errors='coerce').fillna(0).astype(int)
                df_ds['quarter'] = pd.to_numeric(df_ds['quarter'], errors='coerce').fillna(0).astype(int)

                # 1. è´´ä¸Š Mapping ä¿¡æ¯
                df_ds_mapped = pd.merge(
                    df_ds,
                    df_map,
                    left_on='Lender_Name',
                    right_on='Lender_Name_Input',
                    how='inner'
                )

                # 2. ç‚¸å¼€ Top 5ï¼Œæ„å»º RSSD -> DealScan çš„åå‘æŸ¥æ‰¾è¡¨
                lookup_records = []
                for i in range(1, 6):  # éå† Match1 åˆ° Match5
                    rssd_col = f'Match{i}_RSSD'
                    if rssd_col not in df_ds_mapped.columns: continue

                    # æå–è¯¥åæ¬¡æœ‰ RSSD çš„è®°å½•
                    temp = df_ds_mapped[df_ds_mapped[rssd_col].notna()].copy()
                    temp['Target_RSSD'] = temp[rssd_col]

                    # åªä¿ç•™è¿™ä¸€æ­¥éœ€è¦çš„åˆ—
                    subset = temp[['year', 'quarter', 'Lender_Name', 'Lender_Id', 'Target_RSSD']]
                    lookup_records.append(subset)

                if lookup_records:
                    df_lookup = pd.concat(lookup_records, ignore_index=True)
                    # å»é‡ï¼šå¦‚æœåŒä¸€ä¸ª RSSD åœ¨åŒä¸€å¹´åŒä¸€å­£åº¦ å¯¹åº”äº† å¤šæ¡ DealScan è®°å½•
                    # ä¸ºäº†è¾“å‡ºæ•´æ´ï¼Œè¿™é‡Œä¸å»é‡ï¼Œä¿ç•™æ‰€æœ‰ DealScan çš„ Lender_Name
                    # å¦‚æœéœ€è¦ä¸€å¯¹ä¸€ï¼Œå¯ä»¥åœ¨è¿™é‡Œ drop_duplicates

            except Exception as e:
                print(f"   âš ï¸ å¤„ç† DealScan å¤±è´¥: {e}")

        # --- 3.3 æœ€ç»ˆåˆå¹¶ ---
        if not df_lookup.empty:
            df_final = pd.merge(
                df_call,
                df_lookup,
                left_on=['rssdid', 'year', 'quarter'],
                right_on=['Target_RSSD', 'year', 'quarter'],
                how='left'
            )
        else:
            df_final = df_call.copy()
            df_final['Lender_Name'] = None
            df_final['Lender_Id'] = None

        # --- 3.4 æç®€è¾“å‡º ---
        # æŒ‡å®šè¾“å‡ºåˆ—é¡ºåº
        final_cols = ['year', 'quarter', 'name', 'rssdid', 'Lender_Name', 'Lender_Id']

        # ç¡®ä¿åˆ—éƒ½å­˜åœ¨
        for c in final_cols:
            if c not in df_final.columns: df_final[c] = None

        df_output = df_final[final_cols]

        matched_count = df_output['Lender_Name'].notna().sum()
        print(f"   âœ… æˆåŠŸå…³è”: {matched_count} è¡Œ")

        if not os.path.exists(config.DATA_FINAL): os.makedirs(config.DATA_FINAL)
        output_file = os.path.join(config.DATA_FINAL, f"merged_panel_{year}.csv")
        df_output.to_csv(output_file, index=False)
        print(f"   ğŸ’¾ ä¿å­˜è‡³: {output_file}")

    print("\nğŸ‰ æ‰€æœ‰å¹´ä»½å¤„ç†å®Œæˆï¼")


if __name__ == "__main__":
    run()