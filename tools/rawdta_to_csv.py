import pandas as pd
import os
import csv
import re
import platform
import traceback

# ======================== é…ç½®åŒºï¼ˆç›´æ¥ä¿®æ”¹è¿™é‡Œçš„å‚æ•°å³å¯ï¼‰========================
# è¾“å…¥æ–‡ä»¶å¤¹åˆ—è¡¨ï¼šæ”¯æŒå¤šä¸ªæ–‡ä»¶å¤¹ï¼ˆæ–°å¢/åˆ é™¤åªéœ€æ”¹è¿™ä¸ªåˆ—è¡¨ï¼‰
INPUT_DIRS = [
    r"../data/raw/call",  # ç¬¬ä¸€ä¸ªdtaæ–‡ä»¶å¤¹
    r"../data/raw/dealscan"  # ç¬¬äºŒä¸ªdtaæ–‡ä»¶å¤¹
]
# å¯¹åº”çš„è¾“å‡ºç›®å½•åˆ—è¡¨
OUTPUT_DIRS = [
    r"../data/raw/call_csv",  # ç¬¬ä¸€ä¸ªè¾“å‡ºç›®å½•
    r"../data/raw/dealscan_csv"  # ç¬¬äºŒä¸ªè¾“å‡ºç›®å½•
]
ENCODING = "gbk"  # CSVç¼–ç ï¼šExcelå…¼å®¹ç”¨gbkï¼Œé€šç”¨ç”¨utf-8
SKIP_EXISTING_CSV = True  # æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„CSVæ–‡ä»¶ï¼ˆé¿å…é‡å¤è½¬æ¢ï¼‰
CHUNKSIZE = 10000  # å¤§æ–‡ä»¶åˆ†å—å¤§å°ï¼ˆé»˜è®¤1ä¸‡è¡Œ/å—ï¼Œ0è¡¨ç¤ºä¸åˆ†å—ï¼‰
RECURSIVE = True  # æ˜¯å¦é€’å½’éå†å­æ–‡ä»¶å¤¹ä¸­çš„dtaæ–‡ä»¶
# ================================================================================

# é€‚é…ç³»ç»Ÿè·¯å¾„åˆ†éš”ç¬¦
SEP = '\\' if platform.system() == 'Windows' else '/'


# å¼ºåˆ¶æ£€æŸ¥å¹¶å®‰è£…pyreadstatï¼ˆæ ¸å¿ƒä¿®å¤ï¼šè§£å†³è€æ—§DTAè§£æé—®é¢˜ï¼‰
def install_pyreadstat():
    """è‡ªåŠ¨å®‰è£…pyreadstatï¼ˆå¦‚æœæœªå®‰è£…ï¼‰"""
    try:
        import pyreadstat
        print("âœ… pyreadstatå·²å®‰è£…ï¼Œç‰ˆæœ¬ï¼š", pyreadstat.__version__)
        return True
    except ImportError:
        print("ğŸ“Œ æ­£åœ¨å®‰è£…pyreadstatï¼ˆè§£å†³DTAè§£æé—®é¢˜ï¼‰...")
        try:
            import subprocess
            import sys
            subprocess.check_call([sys.executable, "-m", "pip", "install", "pyreadstat"])
            import pyreadstat
            print("âœ… pyreadstatå®‰è£…æˆåŠŸï¼")
            return True
        except Exception as e:
            print(f"âŒ pyreadstatå®‰è£…å¤±è´¥ï¼š{e}")
            print("è¯·æ‰‹åŠ¨æ‰§è¡Œï¼špip install pyreadstat")
            return False


# åˆå§‹åŒ–pyreadstat
PYREADSTAT_AVAILABLE = install_pyreadstat()


def clean_special_chars(text):
    """æ¸…ç†æ— æ³•ç¼–ç çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚\xa0ã€\u200bç­‰ï¼‰"""
    if pd.isna(text) or text == 'nan' or text is None:
        return ""
    if not isinstance(text, str):
        try:
            return str(text)
        except:
            return ""
    # æ›¿æ¢éæ–­è¡Œç©ºæ ¼ã€é›¶å®½ç©ºæ ¼ç­‰ç‰¹æ®Šå­—ç¬¦ä¸ºæ™®é€šç©ºæ ¼
    text = re.sub(r'[\xa0\u200b\u200c\u200d\u2060\u3000]', ' ', text)
    # ç§»é™¤æ— æ³•ç¼–ç çš„å­—ç¬¦ï¼ˆæ ¹æ®æŒ‡å®šç¼–ç è¿‡æ»¤ï¼‰
    try:
        text.encode(ENCODING)
    except UnicodeEncodeError:
        text = ''.join([c for c in text if c.encode(ENCODING, errors='ignore')])
    return text.strip()


def validate_file_size(file_path, min_size=10):
    """æ ¡éªŒæ–‡ä»¶å¤§å°ï¼ˆè‡³å°‘10å­—èŠ‚ï¼Œé¿å…ç©ºæ–‡ä»¶ï¼‰"""
    if not os.path.exists(file_path):
        return False
    return os.path.getsize(file_path) >= min_size


def dta_to_csv(dta_file_path, csv_file_path, encoding='utf-8-sig'):
    """
    ä¿®å¤ç‰ˆè½¬æ¢å‡½æ•°ï¼ˆé’ˆå¯¹ä¸­æ–‡è·¯å¾„ä¼˜åŒ–ï¼‰ï¼š
    é€šè¿‡ä¸´æ—¶åˆ‡æ¢å·¥ä½œç›®å½•ï¼Œè§£å†³ pyreadstat æ— æ³•è¯»å–ä¸­æ–‡è·¯å¾„çš„é—®é¢˜ã€‚
    """
    import os
    import pandas as pd

    # è®°å½•å½“å‰å·¥ä½œç›®å½•ï¼Œä»¥ä¾¿ç¨ååˆ‡å›æ¥
    original_cwd = os.getcwd()

    # åˆ†ç¦»å‡º æ–‡ä»¶å¤¹è·¯å¾„ å’Œ æ–‡ä»¶å
    file_dir = os.path.dirname(dta_file_path)
    file_name = os.path.basename(dta_file_path)

    try:
        # 1. å°è¯•ä½¿ç”¨ Pandas åŸç”Ÿè¯»å– (Pandas å¯¹ä¸­æ–‡è·¯å¾„æ”¯æŒè¾ƒå¥½)
        try:
            df = pd.read_stata(dta_file_path)
        except Exception:
            # 2. å¦‚æœ Pandas å¤±è´¥ï¼Œä½¿ç”¨ pyreadstat (é…åˆâ€œåˆ‡æ¢ç›®å½•å¤§æ³•â€è§£å†³ä¸­æ–‡è·¯å¾„é—®é¢˜)
            if not PYREADSTAT_AVAILABLE:
                return False, "Pandasè¯»å–å¤±è´¥ä¸”æœªå®‰è£…pyreadstat"

            import pyreadstat

            # ã€å…³é”®æ­¥éª¤ã€‘åˆ‡æ¢åˆ°æ•°æ®æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
            os.chdir(file_dir)

            # åªè¯»å–æ–‡ä»¶å (ä¸å¸¦ä¸­æ–‡è·¯å¾„)
            df, meta = pyreadstat.read_dta(file_name)

        # --- ä»¥ä¸‹æ˜¯é€šç”¨çš„æ¸…æ´—å’Œä¿å­˜é€»è¾‘ ---
        if df.empty:
            return False, "DTAæ–‡ä»¶ä¸ºç©º"

        # æ¸…æ´—ç‰¹æ®Šå­—ç¬¦
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].apply(clean_special_chars)

        # å†™å…¥ CSV
        df.to_csv(
            csv_file_path,
            index=False,
            encoding=encoding,
            sep=',',
            quoting=csv.QUOTE_MINIMAL,
            errors='replace'
        )

        return True, f"æˆåŠŸï¼ˆè¡Œæ•°ï¼š{len(df)}ï¼‰"

    except Exception as e:
        return False, f"è½¬æ¢å¼‚å¸¸ï¼š{str(e)}"

    finally:
        # ã€é‡è¦ã€‘æ— è®ºæˆåŠŸå¤±è´¥ï¼Œå¿…é¡»åˆ‡å›åŸæ¥çš„å·¥ä½œç›®å½•ï¼Œå¦åˆ™åç»­è·¯å¾„å…¨ä¹±
        os.chdir(original_cwd)

def batch_convert_multi_dirs():
    """æ‰¹é‡è½¬æ¢å¤šä¸ªè¾“å…¥æ–‡ä»¶å¤¹çš„dtaæ–‡ä»¶"""
    # å…¨å±€ç»Ÿè®¡
    total_success = 0
    total_fail = 0
    total_skip = 0
    total_files = 0

    print(f"ğŸ“ ç³»ç»Ÿè·¯å¾„åˆ†éš”ç¬¦ï¼š{SEP}")
    print(f"ğŸ“ å¾…å¤„ç†æ–‡ä»¶å¤¹åˆ—è¡¨ï¼š{INPUT_DIRS}")
    print(f"ğŸ“ å¯¹åº”è¾“å‡ºç›®å½•åˆ—è¡¨ï¼š{OUTPUT_DIRS}\n")

    # æ ¡éªŒè¾“å…¥è¾“å‡ºç›®å½•æ•°é‡åŒ¹é…
    if len(INPUT_DIRS) != len(OUTPUT_DIRS):
        print(f"âŒ é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶å¤¹æ•°é‡({len(INPUT_DIRS)})ä¸è¾“å‡ºæ–‡ä»¶å¤¹æ•°é‡({len(OUTPUT_DIRS)})ä¸åŒ¹é…")
        return

    # éå†æ¯ä¸ªè¾“å…¥æ–‡ä»¶å¤¹å’Œå¯¹åº”çš„è¾“å‡ºç›®å½•
    for idx, (input_dir, output_dir) in enumerate(zip(INPUT_DIRS, OUTPUT_DIRS)):
        # æ ‡å‡†åŒ–è·¯å¾„
        input_dir = os.path.abspath(input_dir)
        output_dir = os.path.abspath(output_dir)

        print(f"\n=== å¤„ç†ç¬¬{idx + 1}ç»„æ–‡ä»¶å¤¹ ===")
        print(f"ğŸ” è¾“å…¥ç›®å½•(ç»å¯¹è·¯å¾„): {input_dir}")
        print(f"ğŸ” è¾“å‡ºç›®å½•(ç»å¯¹è·¯å¾„): {output_dir}")
        print(f"   è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.isdir(input_dir)}")

        # æ£€æŸ¥å½“å‰è¾“å…¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.isdir(input_dir):
            print(f"âš ï¸ è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè·³è¿‡ï¼š{input_dir}")
            continue

        # æ˜¾ç¤ºç›®å½•åŸºæœ¬ä¿¡æ¯
        try:
            all_files = os.listdir(input_dir)
            dta_files_in_dir = [f for f in all_files if f.lower().endswith('.dta')]
            print(f"   è¾“å…¥ç›®å½•æ–‡ä»¶æ€»æ•°: {len(all_files)}")
            print(f"   è¾“å…¥ç›®å½•.dtaæ–‡ä»¶æ•°: {len(dta_files_in_dir)}")
            if dta_files_in_dir:
                print(f"   å‰5ä¸ª.dtaæ–‡ä»¶: {dta_files_in_dir[:5]}")
        except Exception as e:
            print(f"   âŒ æ— æ³•è¯»å–è¾“å…¥ç›®å½•å†…å®¹: {e}")
            continue

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        print(f"   è¾“å‡ºç›®å½•å·²åˆ›å»º/å­˜åœ¨: {output_dir}")

        # æ”¶é›†å½“å‰æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰dtaæ–‡ä»¶
        dta_files = []
        walk_func = os.walk(input_dir) if RECURSIVE else [(input_dir, [], os.listdir(input_dir))]

        for root, _, files in walk_func:
            for file in files:
                if file.lower().endswith('.dta'):
                    dta_file_path = os.path.abspath(os.path.join(root, file))
                    # ä¿æŒå­æ–‡ä»¶å¤¹ç»“æ„
                    relative_path = os.path.relpath(root, input_dir)
                    output_subdir = os.path.join(output_dir, relative_path)
                    os.makedirs(output_subdir, exist_ok=True)
                    # æ„å»ºcsvè·¯å¾„
                    csv_file_name = os.path.splitext(file)[0] + '.csv'
                    csv_file_path = os.path.abspath(os.path.join(output_subdir, csv_file_name))
                    dta_files.append((dta_file_path, csv_file_path))

        # ç»Ÿè®¡å½“å‰æ–‡ä»¶å¤¹æ–‡ä»¶æ•°
        total_files += len(dta_files)
        print(f"   æœ€ç»ˆå¾…è½¬æ¢.dtaæ–‡ä»¶æ•°: {len(dta_files)}")

        if not dta_files:
            print(f"âš ï¸ åœ¨æ–‡ä»¶å¤¹ {input_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•.dtaæ–‡ä»¶")
            continue

        # è½¬æ¢å½“å‰æ–‡ä»¶å¤¹çš„dtaæ–‡ä»¶
        success_count = 0
        fail_count = 0
        skip_count = 0
        print(f"ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶å¤¹ {input_dir}ï¼ˆå…±{len(dta_files)}ä¸ªdtaæ–‡ä»¶ï¼‰...")

        for dta_path, csv_path in dta_files:
            dta_filename = os.path.basename(dta_path)
            # è·³è¿‡å·²å­˜åœ¨çš„CSV
            if SKIP_EXISTING_CSV and os.path.exists(csv_path) and validate_file_size(csv_path):
                skip_count += 1
                print(f"â­ï¸ {dta_filename} - CSVå·²å­˜åœ¨ä¸”éç©ºï¼Œè·³è¿‡")
                continue

            # æ‰§è¡Œè½¬æ¢
            success, msg = dta_to_csv(dta_path, csv_path, ENCODING)
            if success:
                success_count += 1
                print(f"âœ… {dta_filename} â†’ {os.path.basename(csv_path)} {msg}")
            else:
                fail_count += 1
                print(f"âŒ {dta_filename} - {msg}")

        # ç´¯åŠ å…¨å±€ç»Ÿè®¡
        total_success += success_count
        total_fail += fail_count
        total_skip += skip_count

        print(f"âœ… æ–‡ä»¶å¤¹ {input_dir} å¤„ç†å®Œæˆï¼šæˆåŠŸ{success_count} | å¤±è´¥{fail_count} | è·³è¿‡{skip_count}")

    # æœ€ç»ˆæ±‡æ€»
    print("\n" + "=" * 60)
    print(f"ğŸ“Š å…¨éƒ¨æ–‡ä»¶å¤¹å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ˆ æ€»è®¡æ‰«æï¼š{total_files} ä¸ªdtaæ–‡ä»¶")
    print(f"âœ… æ€»è®¡æˆåŠŸï¼š{total_success} ä¸ª")
    print(f"âŒ æ€»è®¡å¤±è´¥ï¼š{total_fail} ä¸ª")
    print(f"â­ï¸ æ€»è®¡è·³è¿‡ï¼š{total_skip} ä¸ª")
    print("=" * 60)


if __name__ == '__main__':
    # ä¸»ç¨‹åºå…¥å£
    print("ğŸ“Œ è€æ—§DTAæ–‡ä»¶è½¬æ¢å·¥å…·ï¼ˆå¼ºåˆ¶ä½¿ç”¨pyreadstatï¼‰")
    try:
        batch_convert_multi_dirs()
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸ï¼š{str(e)}")
        traceback.print_exc()
    input("\næŒ‰å›è½¦é”®é€€å‡º...")  # é˜²æ­¢Windowsè¿è¡Œåç›´æ¥å…³é—­çª—å£